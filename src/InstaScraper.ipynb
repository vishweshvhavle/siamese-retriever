{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Instagram with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 1: Download ChromeDriver\n",
    "Now we need to download latest stable release of ChromeDriver from:\n",
    "<br>\n",
    "https://chromedriver.chromium.org/\n",
    "\n",
    "## OPTION 2: Use webdriver_manager instead\n",
    "Or, you can install a library named webdriver_manager that will install it for you:\n",
    "<br>\n",
    "https://pypi.org/project/webdriver-manager/\n",
    "<br>\n",
    "<br>\n",
    "Thank you so much to Avishek2020 for pointing this INREDIBLE alternative on Github:\n",
    "<br>\n",
    "https://github.com/MariyaSha/TwitterBot/issues/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webdriver_manager\n",
    "!pip install wget\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabir\\AppData\\Local\\Temp\\ipykernel_28256\\3738983388.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "#automatically install web driver using the webdriver_manager library\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "#open the webpage\n",
    "driver.get(\"http://www.instagram.com\")\n",
    "\n",
    "#target username\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "#enter username and password\n",
    "username.clear()\n",
    "username.send_keys(\"botnut123\")\n",
    "password.clear()\n",
    "password.send_keys(\"donut525\")\n",
    "\n",
    "#target the login button and click it\n",
    "button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "\n",
    "#We are logged in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadle NOT NOW\n",
    "not_now = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n",
    "#not_now2 = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "keyword = \"vadapav\"\n",
    "driver.get(\"https://www.instagram.com/explore/tags/\" + keyword + \"/\")\n",
    " \n",
    "# Wait for 5 seconds\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scraped images:  41\n"
     ]
    }
   ],
   "source": [
    "#scroll down to scrape more images\n",
    "driver.execute_script(\"window.scrollTo(1, document.body.scrollHeight);\")\n",
    "\n",
    "#target all images on the page\n",
    "images = driver.find_elements(By.TAG_NAME, 'img')\n",
    "images = [image.get_attribute('src') for image in images]\n",
    "images = images[:-2]\n",
    "\n",
    "print('Number of scraped images: ', len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images to computer\n",
    "\n",
    "First we'll create a new folder for our images somewhere on our computer.\n",
    "<br>\n",
    "Then, we'll save all the images there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kabir\\\\Downloads\\\\WebscrapingInstagram-main\\\\WebscrapingInstagram-main\\\\vadapavs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, keyword + \"s\")\n",
    "\n",
    "#create the directory\n",
    "os.mkdir(path)\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download images\n",
    "counter = 0\n",
    "for image in images[3:]:\n",
    "    save_as = os.path.join(path, keyword + str(counter) + '.jpg')\n",
    "    wget.download(image, save_as)\n",
    "    counter += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
